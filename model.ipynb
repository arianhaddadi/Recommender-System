{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "d2WrNiB1Idex"
   },
   "source": [
    "import json\n",
    "import math\n",
    "import time\n",
    "import pandas as pd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h9rO_uwZINw"
   },
   "source": [
    "# Address Classes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RmYyLy8eIzKr"
   },
   "source": [
    "class TripAdvisorAddress:\n",
    "    PERSONALITY_SCORES = \"data/Normalized_pers_scores.csv\"\n",
    "    PERSONALITY_DIFFERENCES_EUCLIDEAN = \"data/personality_differences_euclidean.csv\"\n",
    "    DEVIATIONS = \"data/deviations.csv\"\n",
    "    HELPFULNESS = \"data/helpfulness.csv\"\n",
    "    TRUST_SCORE = \"data/trust_scores.csv\"\n",
    "    ALL_REVIEWS = \"data/reviews.csv\"\n",
    "    NEIGHBOURS_DICT = \"data/neighbours_dict.json\"\n",
    "    EMOTIONS = \"data/emotions.csv\"\n",
    "    TRAIN_SET = \"data/reviews_train_set.csv\"\n",
    "    TRAIN_SET_DICT = \"data/train_set_dict.json\"\n",
    "    TEST_SET = \"data/reviews_test_set.csv\"\n",
    "    TEST_SET_DICT = \"data/test_set_dict.json\"\n",
    "    ITEM_BIASES = \"data/item_biases.json\"\n",
    "    USER_BIASES = \"data/user_biases.json\"\n",
    "\n",
    "\n",
    "class AmazonAddress:\n",
    "    PERSONALITY_SCORES = \"data/Amazon_Normalized_pers_scores.csv\"\n",
    "    PERSONALITY_DIFFERENCES_EUCLIDEAN = \"data/amazon_personality_differences_euclidean.csv\"\n",
    "    PERSONALITY_DIFFERENCES_PEARSON = \"data/amazon_personality_differences_pearson.csv\"\n",
    "    DEVIATIONS = \"data/amazon_deviations.csv\"\n",
    "    HELPFULNESS = \"data/amazon_helpfulness.csv\"\n",
    "    TRUST_SCORE = \"data/amazon_trust_scores.csv\"\n",
    "    ALL_REVIEWS = \"data/amazon_reviews.csv\"\n",
    "    NEIGHBOURS_DICT = \"data/amazon_neighbours_dict.json\"\n",
    "    EMOTIONS = \"data/amazon_emotions.csv\"\n",
    "    TRAIN_SET = \"data/amazon_reviews_train_set.csv\"\n",
    "    TRAIN_SET_DICT = \"data/amazon_train_set_dict.json\"\n",
    "    TEST_SET = \"data/amazon_reviews_test_set.csv\"\n",
    "    TEST_SET_DICT = \"data/amazon_test_set_dict.json\"\n",
    "    ITEM_BIASES = \"data/amazon_item_biases.json\"\n",
    "    USER_BIASES = \"data/amazon_user_biases.json\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0l9XRAXc9WB"
   },
   "source": [
    "# Main Recommender Model Class"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OqEFWI13JZbf"
   },
   "source": [
    "class RecommenderModel:\n",
    "    def __init__(self, isAmazon):\n",
    "        self.address = AmazonAddress if isAmazon else TripAdvisorAddress\n",
    "\n",
    "    def getPersonalityTraits(self):\n",
    "        return [\"Extraversion\", \"Neuroticism\", \"Agreeableness\", \"Conscientiousness\", \"Opennes\"]\n",
    "\n",
    "    def calPersonalityDiff(self):\n",
    "        personalities = pd.read_csv(self.address.PERSONALITY_SCORES)\n",
    "\n",
    "        users = list(personalities[\"username\"])\n",
    "        personality_traits = self.getPersonalityTraits()\n",
    "        personality_matrix = pd.DataFrame(columns=users)\n",
    "        already_calculated_users = set()\n",
    "\n",
    "        for user in users:\n",
    "            personality_series = list()\n",
    "            for destination in users:\n",
    "                if user == destination:\n",
    "                    personality_series.append(1)\n",
    "                elif destination in already_calculated_users:\n",
    "                    personality_series.append(personality_matrix.loc[destination][user])\n",
    "                else:\n",
    "                    user_emotions = personalities.loc[personalities[\"username\"] == user].iloc[0]\n",
    "                    # user_emotions_mean = user_emotions[personality_traits].mean()\n",
    "                    destination_emotions = personalities.loc[personalities[\"username\"] == destination].iloc[0]\n",
    "                    # destination_emotions_mean = destination_emotions[personality_traits].mean()\n",
    "\n",
    "                    # numerator_sum, denominator_sum_user, denominator_sum_destination = 0, 0, 0\n",
    "                    diff = 0\n",
    "                    for personality_trait in personality_traits:\n",
    "                        # user_emotion, destination_emotion = user_emotions[personality_trait], destination_emotions[personality_trait]\n",
    "\n",
    "                        # numerator_sum += (user_emotion - user_emotions_mean) * (destination_emotion - destination_emotions_mean)\n",
    "                        # denominator_sum_user += (user_emotion - user_emotions_mean) ** 2\n",
    "                        # denominator_sum_destination += (destination_emotion - destination_emotions_mean) ** 2\n",
    "\n",
    "                        diff += math.pow(user_emotions[personality_trait] - destination_emotions[personality_trait], 2)\n",
    "\n",
    "                    # correlation = (numerator_sum / math.sqrt(denominator_sum_user * denominator_sum_destination) + 1) / 2\n",
    "                    # personality_series.append(correlation)\n",
    "                    personality_series.append(1 - math.sqrt(diff))\n",
    "\n",
    "            already_calculated_users.add(user)\n",
    "            series = pd.Series(data=personality_series, index=users, name=user)\n",
    "            personality_matrix = personality_matrix.append(series)\n",
    "        personality_matrix.to_csv(self.address.PERSONALITY_DIFFERENCES_EUCLIDEAN)\n",
    "\n",
    "\n",
    "    def calHelpfulness(self, skewness, K):\n",
    "        return K / (1 + math.e ** -(K * skewness))\n",
    "\n",
    "\n",
    "    def calEmotionDiff(self, user_reviewed_hotels, destination_reviewed_hotels, common_hotels):\n",
    "        sum = 0\n",
    "        emotions = ['Angry', 'Fear', 'Happy', 'Sad', 'Surprise']\n",
    "        for hotel in common_hotels:\n",
    "            user_review_emotions = user_reviewed_hotels[hotel][\"emotion\"]\n",
    "            destination_review_emotions = destination_reviewed_hotels[hotel][\"emotion\"]\n",
    "\n",
    "            diff = 0\n",
    "            for emotion in emotions:\n",
    "                diff += math.pow(user_review_emotions[emotion] - destination_review_emotions[emotion], 2)\n",
    "\n",
    "            sum += math.sqrt(diff)\n",
    "        return 1 - (sum / len(common_hotels))\n",
    "\n",
    "\n",
    "    def calFactors(self, reviews, helpfulness_k, command):\n",
    "        users = reviews.keys()\n",
    "\n",
    "        if command[\"H\"]:\n",
    "            helpfulness_matrix = pd.DataFrame(columns=users)\n",
    "        if command[\"D\"]:\n",
    "            deviation_matrix = pd.DataFrame(columns=users)\n",
    "        if command[\"E\"]:\n",
    "            emotion_matrix = pd.DataFrame(columns=users)\n",
    "\n",
    "        already_calculated_users = set()\n",
    "\n",
    "        for user in users:\n",
    "            if command[\"H\"]:\n",
    "                helpfulness_series = list()\n",
    "            if command[\"D\"]:\n",
    "                deviation_series = list()\n",
    "            if command[\"E\"]:\n",
    "                emotion_series = list()\n",
    "\n",
    "            for destination in users:\n",
    "                if user == destination:\n",
    "                    if command[\"H\"]:\n",
    "                        helpfulness_series.append(1)\n",
    "                    if command[\"D\"]:\n",
    "                        deviation_series.append(1)\n",
    "                    if command[\"E\"]:\n",
    "                        emotion_series.append(1)\n",
    "\n",
    "                elif destination in already_calculated_users:\n",
    "                    if command[\"H\"]:\n",
    "                        helpfulness_series.append(helpfulness_matrix.loc[destination][user])\n",
    "                    if command[\"D\"]:\n",
    "                        deviation_series.append(deviation_matrix.loc[destination][user])\n",
    "                    if command[\"E\"]:\n",
    "                        emotion_series.append(emotion_matrix.loc[destination][user])\n",
    "\n",
    "                else:\n",
    "                    user_reviews = reviews[user]\n",
    "                    destination_reviews = reviews[destination]\n",
    "\n",
    "                    if command[\"H\"]:\n",
    "                        user_helpfulness = self.calHelpfulness(user_reviews[\"skewness\"], helpfulness_k)\n",
    "                        destination_helpfulness = self.calHelpfulness(destination_reviews[\"skewness\"], helpfulness_k)\n",
    "\n",
    "                    user_reviewed_hotels = user_reviews[\"reviews\"]\n",
    "                    destination_reviewed_hotels = destination_reviews[\"reviews\"]\n",
    "\n",
    "                    num_of_common_reviews = 0\n",
    "                    sum_of_deviation = 0\n",
    "                    common_hotels = list()\n",
    "\n",
    "                    for hotel in user_reviewed_hotels:\n",
    "                        if hotel in destination_reviewed_hotels:\n",
    "                            common_hotels.append(hotel)\n",
    "                            num_of_common_reviews += 1\n",
    "                            sum_of_deviation += (1 - abs(user_reviewed_hotels[hotel][\"deviation\"] - destination_reviewed_hotels[hotel][\"deviation\"]))\n",
    "\n",
    "                    if num_of_common_reviews == 0:\n",
    "                        if command[\"H\"]:\n",
    "                            helpfulness_series.append(0)\n",
    "                        if command[\"D\"]:\n",
    "                            deviation_series.append(0)\n",
    "                        if command[\"E\"]:\n",
    "                            emotion_series.append(0)\n",
    "\n",
    "                    else:\n",
    "                        if command[\"H\"]:\n",
    "                            helpfulness_series.append((1 - abs(user_helpfulness - destination_helpfulness)) / num_of_common_reviews)\n",
    "                        if command[\"D\"]:\n",
    "                            deviation_series.append(sum_of_deviation / num_of_common_reviews)\n",
    "                        if command[\"E\"]:\n",
    "                            emotion_series.append(self.calEmotionDiff(user_reviewed_hotels, destination_reviewed_hotels, common_hotels))\n",
    "\n",
    "            already_calculated_users.add(user)\n",
    "\n",
    "            if command[\"H\"]:\n",
    "                helpfulness_series = pd.Series(data=helpfulness_series, index=users, name=user)\n",
    "                helpfulness_matrix = helpfulness_matrix.append(helpfulness_series)\n",
    "            if command[\"D\"]:\n",
    "                deviation_series = pd.Series(data=deviation_series, index=users, name=user)\n",
    "                deviation_matrix = deviation_matrix.append(deviation_series)\n",
    "            if command[\"E\"]:\n",
    "                emotion_series = pd.Series(data=emotion_series, index=users, name=user)\n",
    "                emotion_matrix = emotion_matrix.append(emotion_series)\n",
    "\n",
    "        if command[\"H\"]:\n",
    "            helpfulness_matrix.to_csv(self.address.HELPFULNESS)\n",
    "        if command[\"D\"]:\n",
    "            deviation_matrix.to_csv(self.address.DEVIATIONS)\n",
    "        if command[\"E\"]:\n",
    "            emotion_matrix.to_csv(self.address.EMOTIONS)\n",
    "\n",
    "\n",
    "    def calDeviation(self, user_rating, average_rating, N):\n",
    "        if user_rating == 0:\n",
    "            return 0\n",
    "        return (-1 / N) * abs(user_rating - average_rating)\n",
    "\n",
    "\n",
    "    def generateReviewsDict(self, reviews, generate_new_one=True):\n",
    "        if not generate_new_one:\n",
    "            with open(self.address.TRAIN_SET_DICT) as file:\n",
    "                return json.loads(file.readline())\n",
    "        else:\n",
    "            users_reviews = dict()\n",
    "            average_rating = float(reviews[\"rating\"].mean())\n",
    "            users = reviews[\"username\"].unique()\n",
    "\n",
    "            for user in users:\n",
    "                user_reviews = reviews.loc[reviews[\"username\"] == user]\n",
    "                reviewed_hotels = user_reviews[\"item\"]\n",
    "\n",
    "                sum_of_helpfulness = float(user_reviews[\"helpfulness\"].sum())\n",
    "                sum_of_sentiments = float(user_reviews[\"sentiment\"].sum())\n",
    "                sum_of_ratings = float(user_reviews[\"rating\"].sum())\n",
    "\n",
    "                reviews_dict = dict()\n",
    "                for hotel in reviewed_hotels:\n",
    "                    user_review = user_reviews.loc[user_reviews[\"item\"] == hotel]\n",
    "                    user_rating = float(user_review[\"rating\"].iloc[0])\n",
    "                    user_review_emotions_dict = user_review[\"emotions\"].apply(eval).iloc[0]\n",
    "\n",
    "                    reviews_dict[hotel] = dict()\n",
    "                    reviews_dict[hotel][\"deviation\"] = self.calDeviation(user_rating, average_rating, N=4)\n",
    "                    reviews_dict[hotel][\"rating\"] = user_rating\n",
    "                    reviews_dict[hotel][\"emotion\"] = user_review_emotions_dict\n",
    "                    reviews_dict[hotel][\"helpfulness\"] = float(user_review[\"helpfulness\"].iloc[0])\n",
    "                    reviews_dict[hotel][\"sentiment\"] = float(user_review[\"sentiment\"].iloc[0])\n",
    "\n",
    "                users_reviews[user] = dict()\n",
    "                users_reviews[user][\"reviews\"] = reviews_dict\n",
    "                users_reviews[user][\"skewness\"] = sum_of_helpfulness / len(reviewed_hotels)\n",
    "                users_reviews[user][\"ratings_average\"] = sum_of_ratings / len(reviewed_hotels)\n",
    "                users_reviews[user][\"sentiment_average\"] = sum_of_sentiments / len(reviewed_hotels)\n",
    "\n",
    "            with open(self.address.TRAIN_SET_DICT, \"w\") as file:\n",
    "                file.write(json.dumps(users_reviews))\n",
    "\n",
    "            return users_reviews\n",
    "\n",
    "\n",
    "    def calVicinity(self, reviews, user, candidate):\n",
    "        user_reviews = reviews[user][\"reviews\"]\n",
    "        candidate_reviews = reviews[candidate][\"reviews\"]\n",
    "\n",
    "        num_of_common_reviews = 0\n",
    "        for review in user_reviews:\n",
    "            if review in candidate_reviews:\n",
    "                num_of_common_reviews += 1\n",
    "        return num_of_common_reviews\n",
    "\n",
    "\n",
    "    def getNeighbours(self, reviews, K, calculate=True):\n",
    "        if not calculate:\n",
    "            with open(self.address.NEIGHBOURS_DICT) as file:\n",
    "                return json.loads(file.readline())\n",
    "        else:\n",
    "            users_neighbours = dict()\n",
    "            users = reviews.keys()\n",
    "            for user in users:\n",
    "                neighbours_dict = dict()\n",
    "                for candidate in users:\n",
    "                    if candidate != user:\n",
    "                        num_of_common_reviews = self.calVicinity(reviews, user, candidate)\n",
    "                        if num_of_common_reviews in neighbours_dict:\n",
    "                            neighbours_dict[num_of_common_reviews].append(candidate)\n",
    "                        else:\n",
    "                            neighbours_dict[num_of_common_reviews] = [candidate]\n",
    "                keys = list(neighbours_dict.keys())\n",
    "                keys.sort(reverse=True)\n",
    "                neighbours = list()\n",
    "                for key in keys:\n",
    "                    if len(neighbours) + len(neighbours_dict[key]) < K:\n",
    "                        neighbours.extend(neighbours_dict[key])\n",
    "                    else:\n",
    "                        neighbours.extend(neighbours_dict[key][:K - len(neighbours)])\n",
    "                users_neighbours[user] = neighbours\n",
    "\n",
    "            with open(self.address.NEIGHBOURS_DICT, \"w\") as file:\n",
    "                file.write(json.dumps(users_neighbours))\n",
    "\n",
    "            return users_neighbours\n",
    "\n",
    "\n",
    "    def calTrustScore(self, reviews, command):\n",
    "        if command[\"H\"]:\n",
    "            helpfulness_values = pd.read_csv(self.address.HELPFULNESS)\n",
    "            helpfulness_values.columns.values[0] = \"users\"\n",
    "            helpfulness_values = helpfulness_values.set_index(\"users\")\n",
    "\n",
    "        if command[\"D\"]:\n",
    "            deviation_values = pd.read_csv(self.address.DEVIATIONS)\n",
    "            deviation_values.columns.values[0] = \"users\"\n",
    "            deviation_values = deviation_values.set_index(\"users\")\n",
    "\n",
    "        if command[\"E\"]:\n",
    "            emotion_values = pd.read_csv(self.address.EMOTIONS)\n",
    "            emotion_values.columns.values[0] = \"users\"\n",
    "            emotion_values = emotion_values.set_index(\"users\")\n",
    "\n",
    "        if command[\"P\"]:\n",
    "            personality_diffs = pd.read_csv(self.address.PERSONALITY_DIFFERENCES_EUCLIDEAN)\n",
    "            personality_diffs.columns.values[0] = \"users\"\n",
    "            personality_diffs = personality_diffs.set_index(\"users\")\n",
    "\n",
    "        users = reviews.keys()\n",
    "        trust_scores_matrix = pd.DataFrame(columns=users)\n",
    "        already_calculated_users = set()\n",
    "\n",
    "        for user in users:\n",
    "            trust_scores_series = list()\n",
    "            for destination in users:\n",
    "                if user == destination:\n",
    "                    trust_scores_series.append(1)\n",
    "                elif destination in already_calculated_users:\n",
    "                    trust_scores_series.append(trust_scores_matrix.loc[destination][user])\n",
    "                else:\n",
    "                    values_to_average = list()\n",
    "                    if command[\"H\"]:\n",
    "                        values_to_average.append(helpfulness_values[destination][user])\n",
    "                    if command[\"D\"]:\n",
    "                        values_to_average.append(deviation_values[destination][user])\n",
    "                    if command[\"E\"]:\n",
    "                        values_to_average.append(emotion_values[destination][user])\n",
    "                    if command[\"P\"]:\n",
    "                        values_to_average.append(personality_diffs[destination][user])\n",
    "                    if command[\"S\"]:\n",
    "                        values_to_average.append(abs(reviews[user][\"sentiment_average\"] - reviews[destination][\"sentiment_average\"]))\n",
    "\n",
    "                    trust_scores_series.append(sum(values_to_average) / len(values_to_average))\n",
    "\n",
    "            already_calculated_users.add(user)\n",
    "            series = pd.Series(data=trust_scores_series, index=users, name=user)\n",
    "            trust_scores_matrix = trust_scores_matrix.append(series)\n",
    "        trust_scores_matrix.to_csv(self.address.TRUST_SCORE)\n",
    "\n",
    "\n",
    "    def predict(self, test_set_dict, reviews, neighbours, biases, *,\n",
    "                threshold=4, predictions_dict=None, biases_cache=None):\n",
    "        mae, rmse = 0, 0\n",
    "        relevant, recommended, relevant_recommended = 0, 0, 0\n",
    "\n",
    "        trust_scores = pd.read_csv(self.address.TRUST_SCORE)\n",
    "        trust_scores.columns.values[0] = \"username\"\n",
    "        trust_scores = trust_scores.set_index(\"username\")\n",
    "\n",
    "        user_biases = biases[0]\n",
    "        user_biases_cache = biases_cache[0] if (biases_cache is not None) else None\n",
    "        item_biases = biases[1]\n",
    "        item_biases_cache = biases_cache[1] if (biases_cache is not None) else None\n",
    "        users = test_set_dict.keys()\n",
    "        num_of_predicted_items = 0\n",
    "        for user in users:\n",
    "            user_neighbours = neighbours[user]\n",
    "\n",
    "            items_to_predict = test_set_dict[user]\n",
    "\n",
    "            for item in items_to_predict:\n",
    "                num_of_predicted_items += 1\n",
    "                numerator = 0\n",
    "                denominator = 0\n",
    "                neighbours_that_reviewed_item = set()\n",
    "\n",
    "                for neighbour in user_neighbours:\n",
    "                    if item in reviews[neighbour][\"reviews\"]:\n",
    "                        neighbours_that_reviewed_item.add(neighbour)\n",
    "                        neighbour_review = reviews[neighbour][\"reviews\"][item]\n",
    "                        trust_score = trust_scores[user][neighbour]\n",
    "                        bmi = user_biases[neighbour] + reviews[neighbour][\"ratings_average\"] + item_biases[item]\n",
    "\n",
    "                        numerator += trust_score * (neighbour_review[\"rating\"] - bmi)\n",
    "                        denominator += abs(trust_score)\n",
    "\n",
    "                bui = user_biases[user] + reviews[user][\"ratings_average\"] + item_biases[item]\n",
    "                prediction = bui + ((numerator / denominator) if denominator != 0 else 0)\n",
    "                real = items_to_predict[item][\"rating\"]\n",
    "\n",
    "                if denominator != 0:\n",
    "                    if user_biases_cache is not None:\n",
    "                        for neighbour in neighbours_that_reviewed_item:\n",
    "                            if neighbour not in user_biases_cache:\n",
    "                                user_biases_cache[neighbour] = list()\n",
    "                            user_biases_cache[neighbour].append({\n",
    "                                \"denominator\": denominator,\n",
    "                                \"trust_score\": trust_scores[user][neighbour],\n",
    "                                \"prediction\": prediction,\n",
    "                                \"real_rating\": real\n",
    "                            })\n",
    "\n",
    "                    if item_biases_cache is not None:\n",
    "                        for neighbour in neighbours_that_reviewed_item:\n",
    "                            if item not in item_biases_cache:\n",
    "                                item_biases_cache[item] = list()\n",
    "                            item_biases_cache[item].append({\n",
    "                                \"denominator\": denominator,\n",
    "                                \"trust_score\": trust_scores[user][neighbour],\n",
    "                                \"prediction\": prediction,\n",
    "                                \"real_rating\": real\n",
    "                            })\n",
    "\n",
    "                if predictions_dict is not None:\n",
    "                    if user not in predictions_dict:\n",
    "                        predictions_dict[user] = dict()\n",
    "                    predictions_dict[user][item] = prediction\n",
    "\n",
    "                relevant += real >= threshold\n",
    "                recommended += prediction >= threshold\n",
    "                relevant_recommended += real >= threshold and prediction >= threshold\n",
    "\n",
    "                mae += abs(prediction - real)\n",
    "                rmse += ((prediction - real) ** 2)\n",
    "\n",
    "        return {\n",
    "            \"mae\": mae / num_of_predicted_items,\n",
    "            \"rmse\": math.sqrt(rmse / num_of_predicted_items),\n",
    "            \"precision\": relevant_recommended / recommended,\n",
    "            \"recall\": relevant_recommended / relevant,\n",
    "        }\n",
    "\n",
    "    def generateTestSetDict(self, test_set, generate_new_one=True):\n",
    "        if not generate_new_one:\n",
    "            with open(self.address.TEST_SET_DICT) as file:\n",
    "                return json.loads(file.readline())\n",
    "        else:\n",
    "            test_set_dict = dict()\n",
    "            users = test_set[\"username\"].unique()\n",
    "\n",
    "            for user in users:\n",
    "                test_set_dict[user] = dict()\n",
    "\n",
    "                user_reviews = test_set.loc[test_set[\"username\"] == user]\n",
    "\n",
    "                for row in user_reviews.itertuples(index=False):\n",
    "                    item = row[1]\n",
    "                    rating = row[2]\n",
    "                    helpfulness = row[3]\n",
    "                    sentiment = row[4]\n",
    "                    emotion_dict = eval(row[5])\n",
    "\n",
    "                    test_set_dict[user][item] = dict()\n",
    "                    test_set_dict[user][item][\"rating\"] = rating\n",
    "                    test_set_dict[user][item][\"sentiment\"] = sentiment\n",
    "                    test_set_dict[user][item][\"helpfulness\"] = helpfulness\n",
    "                    test_set_dict[user][item][\"emotions\"] = emotion_dict\n",
    "\n",
    "\n",
    "            with open(self.address.TEST_SET_DICT, \"w\") as file:\n",
    "                file.write(json.dumps(test_set_dict))\n",
    "\n",
    "            return test_set_dict\n",
    "\n",
    "    def updateBiases(self, biases, biases_cache, predictions_dict, test_set_dict, lambda_value, learning_rate):\n",
    "        user_biases, item_biases = biases\n",
    "        user_biases_cache, item_biases_cache = biases_cache\n",
    "\n",
    "        for user in test_set_dict:\n",
    "            derivative_as_neighbour = 0\n",
    "            if user in user_biases_cache:\n",
    "                user_caches = user_biases_cache[user]\n",
    "                for cache in user_caches:\n",
    "                    derivative_as_neighbour += 2 * (cache[\"prediction\"] - cache[\"real_rating\"]) * (-cache[\"trust_score\"] / cache[\"denominator\"])\n",
    "\n",
    "            derivative_as_rater = 0\n",
    "            user_predicted_items = test_set_dict[user]\n",
    "            for item in user_predicted_items:\n",
    "                derivative_as_rater += 2 * (predictions_dict[user][item] - user_predicted_items[item][\"rating\"])\n",
    "\n",
    "            derivative = derivative_as_neighbour + derivative_as_rater + 2 * lambda_value * user_biases[user]\n",
    "            user_biases[user] -= learning_rate * derivative / 100\n",
    "\n",
    "        for item in item_biases:\n",
    "            derivative_as_neighbour_item = 0\n",
    "            if item in item_biases_cache:\n",
    "                item_caches = item_biases_cache[item]\n",
    "                for cache in item_caches:\n",
    "                    derivative_as_neighbour_item += 2 * (cache[\"prediction\"] - cache[\"real_rating\"]) * (-cache[\"trust_score\"] / cache[\"denominator\"])\n",
    "\n",
    "            derivative_as_user_item = 0\n",
    "            for user in test_set_dict:\n",
    "                if item in test_set_dict[user]:\n",
    "                    derivative_as_user_item += 2 * (predictions_dict[user][item] - test_set_dict[user][item][\"rating\"])\n",
    "\n",
    "            derivative = derivative_as_neighbour_item + derivative_as_user_item + 2 * lambda_value * item_biases[item]\n",
    "            item_biases[item] -= learning_rate * derivative / 100\n",
    "\n",
    "\n",
    "    def trainBiases(self, test_set_dict, reviews, neighbours, biases, num_of_epochs, lambda_value, learning_rate):\n",
    "        predict_func_args = [test_set_dict, reviews, neighbours, biases]\n",
    "        predictions_dict = dict()\n",
    "        biases_cache = [dict(), dict()]\n",
    "        self.predict(*predict_func_args, predictions_dict=predictions_dict, biases_cache=biases_cache)\n",
    "\n",
    "        for i in range(num_of_epochs):\n",
    "            print(f'epoch {i+1}')\n",
    "            self.updateBiases(biases, biases_cache, predictions_dict, test_set_dict, lambda_value, learning_rate)\n",
    "            biases_cache = [dict(), dict()]\n",
    "            predictions_dict = dict()\n",
    "            self.predict(*predict_func_args, predictions_dict=predictions_dict, biases_cache=biases_cache)\n",
    "\n",
    "\n",
    "    def getBiases(self, test_set_dict, generate_new_ones):\n",
    "        biases = list()\n",
    "        if not generate_new_ones:\n",
    "            with open(self.address.USER_BIASES) as file:\n",
    "                biases.append(json.loads(file.readline()))\n",
    "            with open(self.address.ITEM_BIASES) as file:\n",
    "                biases.append(json.loads(file.readline()))\n",
    "        else:\n",
    "            item_biases = dict()\n",
    "            user_biases = dict()\n",
    "\n",
    "            for user in test_set_dict:\n",
    "                user_biases[user] = 0\n",
    "                for item in test_set_dict[user]:\n",
    "                    item_biases[item] = 0\n",
    "\n",
    "\n",
    "            biases.append(user_biases)\n",
    "            biases.append(item_biases)\n",
    "\n",
    "            with open(self.address.USER_BIASES, \"w\") as file:\n",
    "                file.write(json.dumps(user_biases))\n",
    "            with open(self.address.ITEM_BIASES, \"w\") as file:\n",
    "                file.write(json.dumps(item_biases))\n",
    "\n",
    "        return biases\n",
    "\n",
    "    def prepareSummary(self, predictions_dict, neighbours, test_set_dict, train_set_dict):\n",
    "        trust_scores = pd.read_csv(self.address.TRUST_SCORE)\n",
    "        trust_scores.columns.values[0] = \"username\"\n",
    "        trust_scores = trust_scores.set_index(\"username\")\n",
    "\n",
    "        personality_scores = pd.read_csv(self.address.PERSONALITY_SCORES)\n",
    "        personality_scores.columns.values[0] = \"users\"\n",
    "        personality_scores = personality_scores.set_index(\"users\")\n",
    "\n",
    "        columns =   ['username', 'item', 'rating', 'helpfulness', 'emotions', 'sentiment',\n",
    "                     'neighbour_username', 'neighbour_rating', 'neighbour_helpfulness',\n",
    "                     'neighbour_emotions', 'neighbour_sentiment', 'neighbour_text',\n",
    "                     'predicted_rating', 'baseline_predict', 'Extraversion', 'Neuroticism',\n",
    "                     'Agreeableness', 'Conscientiousness', 'Opennes', 'trust_score_baseline',\n",
    "                     'trust_score_enhanced', 'neighbour_Extraversion', 'neighbour_Neuroticism',\n",
    "                     'neighbour_Agreeableness', 'neighbour_Conscientiousness',\n",
    "                     'neighbour_Opennes']\n",
    "        summary = pd.DataFrame(columns=columns)\n",
    "\n",
    "        for user in test_set_dict:\n",
    "            user_neighbours = neighbours[user]\n",
    "            for item in test_set_dict[user]:\n",
    "                for neighbour in user_neighbours:\n",
    "                    if item in train_set_dict[neighbour][\"reviews\"]:\n",
    "                        user_personality = personality_scores.loc[personality_scores[\"username\"] == user].iloc[0]\n",
    "                        neighbour_personality = personality_scores.loc[personality_scores[\"username\"] == neighbour].iloc[0]\n",
    "                        # user_review = train_set_dict[user][item]\n",
    "                        neighbour_review = train_set_dict[neighbour][\"reviews\"][item]\n",
    "                        summary = summary.append({\n",
    "                            'username': user,\n",
    "                            'item': item,\n",
    "                            'rating': test_set_dict[user][item][\"rating\"],\n",
    "                            'helpfulness': test_set_dict[user][item][\"helpfulness\"],\n",
    "                            'emotions': test_set_dict[user][item][\"emotions\"],\n",
    "                            'sentiment':  test_set_dict[user][item][\"sentiment\"],\n",
    "                            'neighbour_username': neighbour,\n",
    "                            'neighbour_rating': neighbour_review[\"rating\"],\n",
    "                            'neighbour_helpfulness': neighbour_review[\"helpfulness\"],\n",
    "                            'neighbour_emotions': neighbour_review[\"emotion\"],\n",
    "                            'neighbour_sentiment': neighbour_review[\"sentiment\"],\n",
    "                            # 'neighbour_text':,\n",
    "                            'predicted_rating': predictions_dict[user][item],\n",
    "                            # 'baseline_predict': predictions_dict[user][item],\n",
    "                            'Extraversion': user_personality[\"Extraversion\"],\n",
    "                            'Neuroticism': user_personality[\"Neuroticism\"],\n",
    "                            'Agreeableness': user_personality[\"Agreeableness\"],\n",
    "                            'Conscientiousness': user_personality[\"Conscientiousness\"],\n",
    "                            'Opennes': user_personality[\"Opennes\"],\n",
    "                            # 'trust_score_baseline': trust_scores[user][neighbour],\n",
    "                            'trust_score_enhanced': trust_scores[user][neighbour],\n",
    "                            'neighbour_Extraversion': neighbour_personality[\"Extraversion\"],\n",
    "                            'neighbour_Neuroticism': neighbour_personality[\"Neuroticism\"],\n",
    "                            'neighbour_Agreeableness': neighbour_personality[\"Agreeableness\"],\n",
    "                            'neighbour_Conscientiousness': neighbour_personality[\"Conscientiousness\"],\n",
    "                            'neighbour_Opennes': neighbour_personality[\"Opennes\"]\n",
    "                        }, ignore_index=True)\n",
    "\n",
    "        summary.to_csv(\"data/report.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "    def calFeaturesAndPredict(self, train_set, test_set, command):\n",
    "        reviews = self.generateReviewsDict(train_set, generate_new_one=True)\n",
    "\n",
    "        neighbours = self.getNeighbours(reviews, K=20, calculate=True)\n",
    "\n",
    "        self.calFactors(reviews, helpfulness_k=1, command=command)\n",
    "\n",
    "        self.calTrustScore(reviews, command=command)\n",
    "\n",
    "        test_set_dict = self.generateTestSetDict(test_set, generate_new_one=True)\n",
    "\n",
    "        biases = self.getBiases(test_set_dict, generate_new_ones=True)\n",
    "\n",
    "        self.trainBiases(test_set_dict, reviews, neighbours, biases, num_of_epochs=150, lambda_value=0.2, learning_rate=0.1)\n",
    "\n",
    "        predictions_dict = dict()\n",
    "        predictions_res = self.predict(test_set_dict, reviews, neighbours, biases, predictions_dict=predictions_dict)\n",
    "\n",
    "        # prepareSummary(predictions_dict, neighbours, test_set_dict, reviews)\n",
    "\n",
    "        return predictions_res\n",
    "\n",
    "\n",
    "    def splitTrainTest(self, all_reviews, numOfReviewsPerUserTestSet):\n",
    "        users = all_reviews[\"username\"].unique()\n",
    "        samples = set()\n",
    "        for user in users:\n",
    "            user_reviews = all_reviews.loc[all_reviews[\"username\"] == user]\n",
    "            if len(user_reviews) == numOfReviewsPerUserTestSet:\n",
    "                continue\n",
    "            choices = list(user_reviews.index.values)[:numOfReviewsPerUserTestSet]\n",
    "            # choices = random.sample(list(user_reviews.index.values), k=numOfReviewsPerUserTestSet)\n",
    "            assert len(choices) == numOfReviewsPerUserTestSet\n",
    "            for choice in choices:\n",
    "                samples.add(choice)\n",
    "\n",
    "        test_set = all_reviews.loc[samples]\n",
    "        train_set = all_reviews.loc[set(all_reviews.index.values) - samples]\n",
    "\n",
    "        train_set.to_csv(self.address.TRAIN_SET, index=False)\n",
    "        test_set.to_csv(self.address.TEST_SET, index=False)\n",
    "\n",
    "\n",
    "\n",
    "    def getCommands(self):\n",
    "        commands = [{\n",
    "            \"D\": True,\n",
    "            \"H\": False,\n",
    "            \"S\": True,\n",
    "            \"E\": False,\n",
    "            \"P\": True,\n",
    "            \"Coeff\": False\n",
    "        }]\n",
    "        return commands\n",
    "\n",
    "\n",
    "    def start(self):\n",
    "        all_reviews = pd.read_csv(self.address.ALL_REVIEWS)\n",
    "\n",
    "        commands = self.getCommands()\n",
    "        for command in commands:\n",
    "\n",
    "            # splitTrainTest(all_reviews, numOfReviewsPerUserTestSet=1)\n",
    "\n",
    "            train_set = pd.read_csv(self.address.TRAIN_SET)\n",
    "            test_set = pd.read_csv(self.address.TEST_SET)\n",
    "\n",
    "            print(f\"Data Check: Train Set Length = {len(train_set)}, Test Set Length = {len(test_set)}, Total Length = {len(all_reviews)}\")\n",
    "\n",
    "            accuracyParams = self.calFeaturesAndPredict(train_set, test_set, command)\n",
    "\n",
    "            self.printResults(command=command, accuracyParams=accuracyParams)\n",
    "\n",
    "\n",
    "    def printResults(self, command, accuracyParams):\n",
    "        factors = list(command.keys())[:-1]\n",
    "        factorsToFactorsMap = {\n",
    "            \"P\": \"Personality\",\n",
    "            \"D\": \"Deviation\",\n",
    "            \"H\": \"Helpfulness\",\n",
    "            \"E\": \"Emotion\",\n",
    "            \"S\": \"Sentiment\",\n",
    "        }\n",
    "        result = \"\"\n",
    "        for factor in factors:\n",
    "            if command[factor]:\n",
    "                result += factorsToFactorsMap[factor] + \"-\"\n",
    "\n",
    "        result += f', RMSE = {accuracyParams[\"rmse\"]}, MAE={accuracyParams[\"mae\"]}, '\n",
    "        result += f'Precision={accuracyParams[\"precision\"]}, Recall={accuracyParams[\"recall\"]}'\n",
    "\n",
    "        print(result)\n",
    "\n",
    "    def run(self):\n",
    "        # self.personality()\n",
    "        self.run()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khTxuyQYZM2m"
   },
   "source": [
    "# Main Run"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iA5WaquoXcvZ"
   },
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = RecommenderModel(isAmazon=False)\n",
    "model.run()\n",
    "\n",
    "print(f\"Elapsed Time = {round((time.time() - start_time) / 3600, 2)} hours\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}